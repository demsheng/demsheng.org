[
{
	"uri": "https://sheng.geovbox.com/git/init/",
	"title": "搭建Git服务器",
	"tags": [],
	"description": "",
	"content": "  在服务器\n git init --bare ~/git/sample.git   克隆项目到本地\n git clone zhangsan@ip:~/git/sample.git   "
},
{
	"uri": "https://sheng.geovbox.com/os/win10_ubuntu18/",
	"title": "win10 ubuntu18 双系统安装",
	"tags": [],
	"description": "",
	"content": "以 dell G7 为例 参考 https://www.cnblogs.com/iamnewsea/p/7701464.html\n1. win10中，分区, 分出5G（FAT32格式）放ubuntu安装文件， 100G用来安装ubuntu 2. win10中，将 ubuntu.iso 解压到 5G的盘中 3. 安装 EasyUEFI，添加启动项，设置5G盘为启动项  EasyUEFI个人版是免费的，可以在官网或友链下载： http://www.easyuefi.com/index-cn.html，下载完后双击运行安装， 在出来的安装对话框中，一路点“继续、确定、完成”，一般默认选中了简体中文；\n安装完自动运行，或双击桌面上图标运行，进入主窗口，再点“管理EFI启动项” 3.在出来程序窗口中间栏，点击第二个绿色加号图标的“添加新项目”；  在出来的面板上边类型里选择Linux，右边文本框里输入名称“Ubuntu”，然后在中间的分区图表中，选中后边的FAT32分区，上边有个圆点；  再点右下角的“浏览文件”按钮，在面板中依次点开加号，找到“\\EFI\\BOOT\\grubx64.efi”，点“确定”；  点“确定”返回主窗口，在左边的启动列表里，选中“Ubuntu”，点中间第一个绿色向上箭头，调到第一位，点击返回主窗口；  关闭所有窗口，重启计算机，可以按“win键+R”调出运行框，输入 shutdown.exe -f -r -t 0  4. F12启动，安装ubuntu，新建800M的分区给/boot，100G给/，设置启动项安装到/boot所在分区，/sda5? "
},
{
	"uri": "https://sheng.geovbox.com/vbox/",
	"title": "ZDEM/VBOX应力应变处理",
	"tags": [],
	"description": "",
	"content": "应力应变处理  vboxdaily -s ./datass 计算应力应变 vboxss --dir ./datass 绘制应力应变    vboxdaily push.py\nvboxdaily 计算，将生成 ./data 文件夹\n  vbox2jpg --dir=./data\n生成jpg，生成计算过程图．注意：这里，只需指定 --dir ，不加其它任何参数．\n  新建datass文件夹，根据jpg挑选需要计算应力应变的.dat文件，复制到datass文件夹中。\n这里，挑选原则如下：\n 刚沉积完，并给定颜色，准备挤压的初始模型，必须。all_0000006000_ini.dat  刚剥蚀完，准备挤压的模型，必须。all_0000036000_ini.dat  沉积稳定，准备挤压前的模型。all_0000058000_ini.dat  沉积过程不要，其它的可酌情选取。    计算应力和应变\n 无沉积和剥蚀 vboxdaily -s ./datass 无沉积和剥蚀 vboxdaily --xmove -1000.0 --ymove -1000.0 -g 400 --leftwallid 1 -s ./datass 有沉积和剥蚀 vboxdaily --xmove -1000.0 --ymove -1000.0 -g 400 --leftwallid 1 --addball --delball -s ./datass  用vboxdaily将dat转换文件格式为.out，供GMT绘图用。注意：基于步骤2，我们知道 --xmove --ymove 应该设置为多少．如果有沉积--addball或者剥蚀--delball过程，需添加相应参数．参数解释：\n-s, --strain-stress DataDir 计算应力应变 从DataDir读取数据，将应力应变输出到DataDir/ss目录 --xmove X 配合-s选项，设置模型x方向偏移位移X，默认0.0。 --ymove Y 配合-s选项，设置模型y方向偏移位移Y，默认0.0。 -g, --grid SIZE 配合-s选项，设置应力应变计算时候，网格的大小SIZE，默认200.0 --leftwallid ID 配合-s选项，设置左边墙ID，该墙左边颗粒均会被删除。如果颗粒被挤出到左边墙之外需要设置该参数。 --rightwallid ID 配合-s选项，设置右边墙ID，该墙右边颗粒均会被删除。如果颗粒被挤出到右边墙之外需要设置该参数。 --addball 配合-s选项，应力应变计算过程中，有新颗粒加入体系（沉积）,默认关闭。 --delball 配合-s选项，应力应变计算过程中，删除了颗粒（剥蚀），默认关闭。   使用GMT绘制应力应变\n  无沉积和剥蚀 vboxss --dir ./datass\n  有沉积和剥蚀 vboxss --dir ./datass --addball ON --delball ON\n  添加 gmt 环境变量\n把以下内容添加到　~/.bashrc 文件尾，\n vi ~/.bashrc\nexport GMT5HOME=/share/home/hwyin/lib/gmt/gmt545 export PATH=${GMT5HOME}/bin:$PATH export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${GMT5HOME}/lib64   使用方法\nvbox 处理完成的应力应变数据，在文件夹 datass 中生成 应力应变数据 ss 。\n在 ex1 文件夹中输入：\nvboxss --dir ./datass 有沉积剥蚀事件：\nvboxss --dir ./datass --addball ON --delball ON 设置x轴最大值 40.0 km，设置y轴最大值 10.0 km，设置颜色条应力最大值400 MPa：\nvboxss --dir ./datass --xmax 40.0 --ymax 10.0 --maxstress 400.0 实例目录结构：\n|-- ex1 |-- lsf1.sh |-- lsf2.sh |-- push.py |-- data |-- all_0000000000_ini.dat |-- ... |-- all_0000005000.dat |-- all_0000058000_ini.dat |-- all_0000108000.dat |-- datass |--ss |-- data |-- *.out |-- all_0000006000_ini.dat |-- all_0000026000.dat 运行完成之后， ss 目录结构如下\n |-- ss |-- data |-- *.out |-- ps |-- *.ps |-- Tmp |-- *.grd |-- *.jpg  data 应力应变原始数据 ps 输出的应力应变图(矢量图) tmp 计算应力应变产生的中间数据 *.jpg 输出的应力应变图(位图)    参数说明：\n --addball ON/OFF 有沉积事件，默认OFF --delball ON/OFF 有剥蚀事件，默认OFF -d, --dir 设置数据所在目录 -h, --help 打印帮助信息 --showcolorbar ON/OFF 绘制颜色条，默认ON --showlable ON/OFF/abc 绘制颜色条，默认OFF，其中abc只给子图命名为abc --stressshear ON/OFF 绘制剪切应力，默认ON --stressmean ON/OFF  绘制平均应力，默认ON --strainshear ON/OFF 绘制变形应变，默认ON --strainvol ON/OFF  绘制体积应变，默认ON --width value 图片宽(cm)，默认14 --xmax value  x轴最大值(km)，默认自动设置 --ymax value y轴最大值(km)，默认自动设置 --maxstress value  最大应力值(MPa)，默认 300 -v, --version 显示版本信息      提交计算 挑选完dat文件后，可用下文的　lsf2.sh 提交计算\n实例  bsub \u0026lt; lsf1.sh 提交，将完成步骤 1和2 新建datass文件夹，将需要处理的dat复制到datass文件夹(自己选dat)　 bsub \u0026lt; lsf2.sh 提交，将完成步骤 4和5 把datass和jpg发给李长圣，等待处理结果！  目录结构：\n|-- ex1 |-- lsf1.sh |-- lsf2.sh |-- push.py |-- data |-- all_0000000000_ini.dat |-- all_0000001000.dat |-- ... |-- all_0000005000.dat |-- all_0000005000_ini.dat |-- all_0000006000.dat |-- all_0000006000_ini.dat |-- all_0000016000.dat |-- all_0000026000.dat |-- all_0000036000.dat |-- all_0000036000_ini.dat |-- all_0000046000.dat |-- all_0000056000.dat |-- all_0000056000_ini.dat |-- all_0000056100.dat |-- ... |-- all_0000057900.dat |-- all_0000058000.dat |-- all_0000058000_ini.dat |-- all_0000068000.dat |-- all_0000078000.dat |-- all_0000088000.dat |-- all_0000098000.dat |-- all_0000108000.dat |-- datass |-- all_0000006000_ini.dat |-- all_0000026000.dat |-- all_0000036000_ini.dat |-- all_0000056000.dat |-- all_0000058000_ini.dat |-- all_0000078000.dat |-- all_0000108000.dat 文件内容：\nlsf1.sh\n#!/bin/bash # #BSUB -J sheng #BSUB -q mpi #BSUB -n 24 #BSUB -R \u0026quot;span[ptile=24]\u0026quot; vboxdaily push.py vbox2jpg -j 24 --dir=./data convert -delay 100 ./data/*[0-9].jpg -loop 0 ./data/process.gif lsf2.sh\n#!/bin/bash # #BSUB -J stress #BSUB -q mpi #BSUB -n 24 #BSUB -R \u0026quot;span[ptile=24]\u0026quot; vboxdaily --xmove -1000.0 --ymove -1000.0 -g 400 -j 24　--leftwallid 1 --addball --delball　-s ./datass push.py\n###################################### # title: 一个实例学会VBOX 加入剥蚀 沉积 演示应力应变处理过程 # date: 2020-06-28 # authors: 李长圣 # E-mail: sheng0619@163.com # www.geovbox.com ####################################### #程序初始化 START #颗粒设为球，计算颗粒体积用4/3*pi*r^3计算 set disk off #设置研究范围 BOX left 0.0 right 42000.0 bottom 0.0 height 12000.0 kn=0e10 ks=0e10 fric 0.00 #设置挡板墙，这里模型采用hertz接触模型，挡板墙的kn ks无效，计算时取颗粒的参数 WALL ID 0, NODES ( 1000.0 , 1000.0 ) ( 41000.0 , 1000.0 ), kn=0e10 ks=0e10 fric 0.0 COLOR black WALL ID 1, NODES ( 1000.0 , 10000.0 ) ( 1000.0 , 1000.0 ), kn=0e10 ks=0e10 fric 0.0 COLOR blue WALL ID 2, NODES ( 41000.0 , 1000.0 ) ( 41000.0 , 10000.0 ), kn=0e10 ks=0e10 fric 0.0 COLOR red #在矩形范围内生成颗粒 GEN NUM 100000.0 rad discrete 60.0 80.0, x ( 1000.0, 41000.0), y ( 1000.0, 10000.0), COLOR black GROUP ball_rand #设置颗粒的微观参数 PROP DENSITY 2.5e3, fric 0.0, shear 2.9e9, poiss 0.2, damp 0.4, hertz #设置时间步及重力加速度 SET DT 5e-2, GRAVITY 0.0, -10.0 #设置每1000步保存一次ps格式的计算结果 SET ps 1000 #设置每1000步保存一次dat格式的计算结果 SET print 1000 #沉积，计算5000步 CYC 5000 #删除4000米以上的颗粒 DEL RANGE y 4000.0 999000.0 #平衡，计算1000步 CYC 1000 #输出包含颗粒的[x y r]信息的初始模型 init_xyr.dat #EXP init_xyr.dat #设置bond粘结，使颗粒具有粘聚力 PROP ebmod 2e8 gbmod 2e8 tstrength 2e7 sstrength 4e7 fric 0.3 #给地层赋上颜色 PROP COLOR lg range y 1000.0 1500.0 PROP COLOR green range y 1500.0 2000.0 PROP COLOR yellow range y 2000.0 2500.0 PROP COLOR red range y 2500.0 3000.0 PROP COLOR black range y 3000.0 3500.0 PROP COLOR mg range y 3500.0 4000.0 PROP COLOR blue range y 4000.0 4500.0 PROP COLOR gb range y 4500.0 5000.0 PROP COLOR violet range y 5000.0 5500.0 #设置挡板墙摩擦系数 WALL id 0 fric 0.3 WALL id 1 fric 0.3 WALL id 2 fric 0.3 #设置墙的挤压速度 x方向速度为2.0 WALL id 1 xv 2.0 #设置墙的挤压量x方向推进3000.0，每挤压2000.0保存一次计算结果 IMPLE wall id 1 xmove 3000.0 save 2000.0 print 1000.0 ps 1000.0 ##################################### 剥蚀 ##################################### # 删除4000米以上的颗粒 DEL RANGE y 4000.0 999000.0 ################################################################################ #设置墙的挤压量x方向推进3000.0，每挤压2000.0保存一次计算结果 IMPLE wall id 1 xmove 2000.0 save 2000.0 print 1000.0 ps 1000.0 ##################################### 沉积 ##################################### #停止挤压，墙的x方向速度改为0.0 WALL id 1 xv 0.0 #沉积。在挤压前端12000～40000.0上方，沉积约 1 km 颗粒。y的范围需要设置为4000-6000。 #经验：颗粒充填满2km范围，沉积之后的地层厚度约为1km GEN NUM 100000.0 rad discrete 60.0 80.0, x ( 10000.0, 41000.0), y ( 4000.0, 6000.0), COLOR gb GROUP sed #设置沉积颗粒 GROUP=sed 的微观参数 PROP DENSITY 2.5e3, fric 0.3, shear 2.9e9, poiss 0.2, damp 0.4, hertz range GROUP sed #计算2000步，让颗粒沉积下来 SET print 100 #每 100 步输出一次计算结果 CYC 2000 ################################################################################ #设置墙的挤压速度 x方向速度为2.0 WALL id 1 xv 2.0 #设置墙的挤压量x方向推进3000.0，每挤压2000.0保存一次计算结果 IMPLE wall id 1 xmove 5000.0 save 5000.0 print 1000.0 ps 1000.0 #计算停止 STOP "
},
{
	"uri": "https://sheng.geovbox.com/rocks/base/",
	"title": "基础",
	"tags": [],
	"description": "",
	"content": "  df -hl 查看磁盘剩余空间\n  chown 账号名称 文件或目录 更改文件拥有者 (chown )\n  chgrp 组名 文件或目录 改变文件的用户组用命令 chgrp\n  df -hl 查看磁盘剩余空间\n  df -h 查看每个根路径的分区大小\n  du -sh [目录名] 返回该目录的大小\n  du -sm [文件夹] 返回该文件夹总M数\n  du -h [目录名] 查看指定文件夹下的所有文件大小（包含子文件夹）\n  gedit ~/.config/user-dirs.dirs Ubuntu 桌面显示路径修改\n  强制修改密码\n 提升权限：su 强制修改密码（无安全性校验）：echo \u0026lsquo;\u0026lt;新密码\u0026gt;\u0026rsquo; | passwd \u0026ndash;stdin \u0026lt;用户名\u0026gt; ，例如：  echo 123456 | passwd --stdin zhangsan ``\n    添加用户\n  adduser -g vbox zhangsan #添加用户 passwd zhangsan # 修改密码 rocks sync users # 同步账户信息，新建用户后必须同步后才生效，如果失败，重启再试  删除用户  userdel -r zhangsan # 删除用户，包括家目录 rocks sync users  修改用户名  usermod -l 新用户名 -d /home/新用户名 -m 老用户名 rocks sync users  权限管理 ll 显示的内容如下：  -rwxrw-r‐-1 root root 1213 Feb 2 09:39 abc `chmod` 改变文件或目录的权限 - `chmod 755 abc` 赋予abc权限rwxr-xr-x - `chmod u=rwx，g=rx，o=rx abc` 同上 **u=用户权限，g=组权限，o=不同组其他用户权限** - `chmod u-x，g+w abc` 给abc去除用户执行的权限，增加组写的权限 - `chmod a+r abc` 给所有用户添加读的权限 - 10个字符确定不同用户能对文件干什么 - 第一个字符代表文件（-）、目录（d），链接（l） - 其余字符每3个一组（rwx），读（r）、写（w）、执行（x） - 第一组rwx：文件所有者的权限是读、写和执行 - 第二组rw-：与文件所有者同一组的用户的权限是读、写但不能执行 - 第三组r--：不与文件所有者同组的其他用户的权限是读不能写和执行 - 也可用数字表示为：r=4，w=2，x=1 因此rwx=4+2+1=7 - 1 表示连接的文件数 - root 表示用户 - root表示用户所在的组 - 1213 表示文件大小（字节） - Feb 2 09:39 表示最后修改日期 - abc 表示文件名  "
},
{
	"uri": "https://sheng.geovbox.com/git/multuser/",
	"title": "多个git账号的登录与切换",
	"tags": [],
	"description": "",
	"content": "Ref https://blog.csdn.net/qq_36602939/article/details/79794686\n  新建user1的SSH Key\n生成密钥\nssh-keygen -t rsa -C \u0026quot;geovbox@163.com\u0026quot; 看见两个文件： id_rsa id_rsa.pub 复制密钥 id_rsa.pub 到git账号里。\n  新建user2的SSH Key\n#新建SSH key： $ cd ~/.ssh ssh-keygen -t rsa -C \u0026quot;sheng0619@163.com\u0026quot; # 新建工作的SSH key # 设置名称为id_rsa_demsheng Enter file in which to save the key (~/.ssh/id_rsa): id_rsa_demsheng 新密钥添加到SSH agent中 因为默认只读取id_rsa，为了让SSH识别新的私钥，需将其添加到SSH agent中：\nssh-add ~/.ssh/id_rsa_demsheng 如果出现Could not open a connection to your authentication agent的错误，就试着用以下命令：\nssh-agent bash ssh-add ~/.ssh/id_rsa_work   修改config文件\n在~/.ssh目录下找到config文件，如果没有就创建：\ntouch config # 创建config 然后修改如下： 我的config配置如下：\n# 该文件用于配置私钥对应的服务器 # Default github user(first@mail.com) Host github.com HostName github.com User git IdentityFile /home/lichangsheng/.ssh/id_rsa # second user(second@mail.com) # 建一个github别名，新建的帐号使用这个别名做克隆和更新 Host demsheng.github.com HostName github.com User git IdentityFile /home/lichangsheng/.ssh/id_rsa_demsheng 其规则就是：从上至下读取config的内容，在每个Host下寻找对应的私钥。这里将GitHub SSH仓库地址中的git@github.com替换成新建的Host别名如：demsheng.github.com，那么原地址是：git@github.com:demsheng/sheng.git，替换后应该是：demsheng.github.com:funpeng/sheng.git.\n  打开新生成的~/.ssh/id_rsa_demsheng.pub文件，将里面的内容添加到GitHub后台。\n  以下命令可以检查当前用户： ssh -T git@github.com ssh -T git@demsheng.github.com\n  以下命令可以检查当前秘钥： ssh-add -l\n  "
},
{
	"uri": "https://sheng.geovbox.com/rocks/auto_mount/",
	"title": "自动挂载",
	"tags": [],
	"description": "",
	"content": "自动挂载 在主节点修改 /etc/fstab\n#2017/11/28 lichangsheng add sdb1 and sdc1 # home /dev/sdb1 /state/sdb1_8T ext3 defaults 0 0 # backup dir /dev/sdc1 /mnt/sdc1_data_backup ext3 defaults 0 0 "
},
{
	"uri": "https://sheng.geovbox.com/rocks/",
	"title": "集群管理",
	"tags": [],
	"description": "",
	"content": "记录了 李长圣在南京大学尹宏伟课题组 Rocks 集群管理经验。\n 基础 自动挂载 配置同步 重启集群 修改家目录 共享主节点磁盘 自动备份 ssh SGE作业管理系统 LSF作业管理系统 PBS作业管理系统 设置用户密码使用期限 IP 登录进入bash rocks 重装 格式化8T硬盘  "
},
{
	"uri": "https://sheng.geovbox.com/dem/",
	"title": "离散元",
	"tags": [],
	"description": "",
	"content": "记录李长圣在开发离散元软件VBOX时的知识。\n 编译VTK  c++  单例模式 https://www.cnblogs.com/CheeseZH/p/5264519.html\n单件模式（SingletonPattern）：确保一个类只有一个实例，并提供一个全局访问点。和全局变量一样方便，又没有全局变量的缺点，即不需要从一开始就创建对象，而是在需要时才创建它。 局部类 嵌套类 http://www.cppblog.com/mzty/archive/2007/05/24/24766.html 前置声明。c++ 两个头文件互相引用    "
},
{
	"uri": "https://sheng.geovbox.com/dem/vtk/",
	"title": "编译vtk，win10+qt5+vtk8",
	"tags": [],
	"description": "",
	"content": "参考 https://blog.csdn.net/annjeff/article/details/88597051\n  编译之前规划\n在进行编译之前先规划好编译中产生的文件所在的目录，清晰的目录结构是一个很不错的习惯。我的做法同其他博主类似，先为VTK新建一个文件夹，将此目录作为VTK的家目录。在VTK目录之下新建四个目录，它们分别是：VTK-8.2.0-src(将下载的源码解压到此目录下)；VTK-8.2.0-build(VTK在编译时生成编译的二进制文件放在此文件夹中)；VTK-8.2.0-Install-VS2017-x64-Release（生成的lib文件include文件放于其中，此即我们需要的库的Release版本）；VTK-8.2.0-Install-VS2017-x64-Debug（生成的lib文件include文件放于其中，此即我们需要的库的Debug版本）。最后需要声明：VTK官网提供了VTK-8.2.0-Data，这是运行VTK示例所需要的数据，一般不需要，下载下来也无妨，看个人需求吧。\n  开始Cmake编译VTK库\n 打开安装的cmake-gui，选择VTK源码路径，以及二进制存放路径，此即我们规划的VTK-8.2.0-src与VTK-8.2.0-bin。然后开始Config即可。 选择Visual Studio 17 2017 Win64（64位版本的VS 2017）编译。选择后点击Finish。 第一次Config完成以后，此时界面会变成红色。我们需要对一些选项进行配置。这一步我们勾选BUILD_EXAMPLES即编译VTK自带的示例文件。当然这不是必须的，勾选编译示例会增加额外的编译时间。但是，BUILD_SHARED_LIBS一定确保是勾选的，VTK-8.2.0默认是勾选的。此项的作用是生成动态共享库DLL。 这一步选择是相当重要的，CMAKE_INSTALL_PREFIX是我们VTK库要安装的位置，亦即VTK编译后生成的库文件所在位置，建议将位置修改为我们规划的VTK-8.2.0-Install-VS2017-x64-Debug文件夹。虽然图中是Release，但是我还是建议选择Debug文件夹，因为我的思路是先生成Release版本的VTK库，生成后，将所有文件全部剪切到VTK-8.2.0-Install-VS2017-x64-Release文件夹下。接下来再次生成Debug版本，就会在Debug文件夹里了。之所以这么做，还是因为我们选择CMAKE_INSTALL_PREFIX路径后不可以改变。 因为我们要使用Qt所以此处要勾选VTK_Group_Qt。 使用第三方的经验告诉我们，Debug版本的库后面一般带d表示是Debug版本。例如：opencv_world400.lib是Release版本的库，opencv_world400d.lib是Debug版本的库。因此，为了区分版本，我们在CMAKE_DEBUG_POSTFIX后面添加d这样进行Debug版本编译时会在库文件名后面多个d。 如果你下载了VTK-8.2.0-Data，在VTK_DATA_STORE中可以选择VTK-8.2.0-Data所在的路径。这一步为非必要步骤。执行完以上步骤以后再次点击Config。 你会发现这里还是有一片红色区域，这里是让我们选择Qt5的位置，基本是Qt_DIR/5.12.0/msvc2017_64/lib/cmake/Qt*,按左侧的名字勾选即可。 确定VTK_QT_VERSION是5版本。然后再次点击Config。 Configuring done后，此时是白色区域，代表没有错误。如果你的界面依旧有红色，返回检查以上哪步没有勾选，一直Config到白色界面位置。此时可以点击Generate。 Generate done后，同样是白色区域，代表没有错误。到这里CMAKE的阶段就已经完成了。    开始VS编译安装VTK\n  Cmake阶段完成以后，找到我们规划的VTK-8.2.0-bin文件夹，找到VTK.sln。打开Visual Studio2017，如果你安装了VAssitX插件（小番茄）建议您暂时关闭该插件，因为会降低速度。此时打开VTK.sln项目，因为项目非常大，文件非常多，所以打开的速度会比较慢。\n  当你发现VS左下角显示就绪时，此时项目已经加载完毕。\n  此时选择【生成】\u0026ndash;\u0026gt;【批生成】。\n  在ALL_BUILD Release x64 栏 勾选 √\u0026mdash;-\u0026gt;点击【生成】。还记得刚刚让你准备的瓜子、花生、电影么，现在派上用场了^ _ ^，因为这一步会执行很长的时间。看电脑配置，一般电脑大约在半小时左右。\n  有木有很开心，终于生成完了。\n  接下来，把刚刚勾选的ALL_BUILD Release后面的√去掉，下拉，在INSTALL Release后面勾选。这一步就是在安装VTK的Release版本。其本质就是生成Release版本的库文件。放心好了，这一步很快的。\n  当你看到这一步的时候，你已经成功的生成了VTK-8.2.0的Release版本的库文件。到哪里去找呢？生成的Release版库文件在我们规划的VTK-8.2.0-Install-VS2017-x64-Debug里面（因为我们Camke时选择的这个文件夹），这时我们需要把文件剪切到VTK-8.2.0-Install-VS2017-x64-Release文件夹里，到这里Release版本生成成功。\n  这便是VTK的库文件\nbin include lib share   你会发现Release版本的后面没有d。我们以后使用VTK进行开发，用的就是这些库文件。\n  如果你需要Debug版本的VTK库，此时需要在【生成】\u0026ndash;\u0026gt;【批生成】里，把刚刚勾选的INSTALL Release后面的√取消。然后可以直接一起勾选ALL_BUILD DEBUG x64 与 INSTALL Debug,生成结束以后，会在VTK-8.2.0-Install-VS2017-x64-Debug文件夹里生成库文件。此时编译阶段完成。\n  生成的Debug版本的库后面带d，以区分Release版本。\n    安装VTK后续配置\nVTK的Release版本与Debug版本的库都已经生成完毕了，此时我们该考虑如何在Qt Creator中使用生成的VTK库。如何在Qt Creator 中使用VTK库，我会在下面一篇文章中详细介绍，这里我们先做一些准备。\n 将VTK Release版本中的QVTKWidgetPlugin放于Qt 的 Designer里 Qt作为图形显示软件，其强大之处在于可以直接绘制UI界面，而VTK是Qt 的好基友，因此为其专门生成来的可用于Qt 的Designer界面绘制的插件。方法也很简单，将Release 版本下 D:\\VTK\\VTK-8.2.0\\VTK-8.2.0-Install-VS2017-x64-Release\\plugins\\designer\\QVTKWidgetPlugin.dll复制到 Qt Creator的D:\\Qt\\5.12.0\\msvc2017_64\\plugins\\designer\\文件夹下，此时单独打开Qt Designer（msvc2017_64版）会发现已经集成了QVTK。可以通过拖动的方式绘制。 将VTK的路径放于系统的Path路径里 【控制面板】\u0026ndash;\u0026gt;【系统和安全】\u0026ndash;【系统】\u0026ndash;\u0026gt;【高级系统设置】\u0026ndash;\u0026gt;【环境变量】，新建，固定写VTK_DIR变量值为VTKConfig.cmake所在的路径，这里是方便后面以Cmake的方式构建VTK程序。    结语\n如果你已经坚持看到这里，而且是已经编译成功，恭喜你，后来人。接下来你可以进行VTK的学习，这里我想向你推荐两本书。你在学习VTK，基本可以判定你是本科及以上学历，如果你英文还好，推荐你看《VTKUsersGuide》VTK官网可以下载pdf，如果你英文有些吃力，可以看《VTK图形图像开发进阶》这本书，国内经典书籍，作者也是较早使用VTK的前辈。总之，希望你可以坚持下去，也希望我的博客可以带给你一点帮助。\n  "
},
{
	"uri": "https://sheng.geovbox.com/git/fork/",
	"title": "fork后，更新到原作者的主分支",
	"tags": [],
	"description": "",
	"content": "Github上 fork了别人的代码 本地更新主分支代码 在GitHub上我们会去fork别人的一个项目，这就在自己的Github上生成了一个与原作者项目互不影响的副本，自己可以将自己Github上的这个项目再clone到本地进行修改，修改后再push，只有自己Github上的项目会发生改变，而原作者项目并不会受影响，避免了原作者项目被污染。但经过一段时间， 有可能作者原来的代码变化很大， 你想接着在他最新的代码上修改， 这时你需要合并原作者的最新代码过来， 让你的项目变成最新的。\n  先克隆项目到本地\n Git clone https://github.com/demsheng/trunk cd trunk   添加原作者项目的 remote 地址， 然后将代码 fetch 过来\n git remote add yade https://github.com/yade/trunk git fetch yade yade 相当于一个别名 查看本地项目目录： git remote -v\n  合并\n git checkout master git merge yade/master 如果有冲突的话，需要丢掉本地分支： git reset –hard yade/master   这时你的当前本地的项目变成和原作者的主项目一样了，可以把它提交到你的GitHub库\ngit commit -am '更新到原作者的主分支' git push origin git push -u origin master -f –强制提交   同步标签\ngit push origin --tags   修改远程仓库地址\ngit remote set-url origin git@demsheng.github.com:demsheng/trunk.git   "
},
{
	"uri": "https://sheng.geovbox.com/rocks/set/",
	"title": "配置同步",
	"tags": [],
	"description": "",
	"content": "集群配置信息同步\nrocks sync users # 同步账户信息，新建用户后必须同步后才生效，如果失败，重启再试 rocks sync config #同步集群配置信息，主机每次更改配置后必须使用该命令，否则会出错 "
},
{
	"uri": "https://sheng.geovbox.com/git/",
	"title": "git",
	"tags": [],
	"description": "",
	"content": "李长圣学习Git的笔记。\n  搭建Git服务器 \n  多个git账号的登录与切换\n  fork后，更新到原作者的主分支\n  修改默认端口号\n  彻底删除文件\n  打标签\n  设置用户\ngit config --global user.name \u0026quot;geovbox\u0026quot;\rgit config --global user.email \u0026quot;geovbox@163.com\u0026quot;\r  重命名文件夹/文件\ngit mv -f content/rocks/advance/ content/rocks/share`\r  修改 Git 远程仓库地址 gedit .git/config\n[core]\rrepositoryformatversion = 0\rfilemode = true\rbare = false\rlogallrefupdates = true\r[remote \u0026quot;origin\u0026quot;]\rfetch = +refs/heads/*:refs/remotes/origin/*\r#设置使用哪个远程库\rurl = ssh://li_changsheng@ip:1234/home/vpost.git\r# url = https://github.com/demsheng/vpost.git\r[branch \u0026quot;master\u0026quot;]\rremote = origin\rmerge = refs/heads/master\r  放弃本地修改，直接覆盖之\ngit fetch --all\rgit reset --hard origin/master\r  回退到某个指定的版本\ngit reset --hard 139dcfaa558e3276b30b6b2e5cbbb9c00bbdca96 #后面的是git提交的历史版本号， `git log` 找到复制下来就行\r  一次 git push 到多个远程库\n需要给远程库添加多个url地址，git的一个远程库 可以对应多个地址，即我能让 远程库origin拥有多个url地址。 方法如下：\n  首先，我们从零开始， 假设你现在想要增加3个远程库地址，分别为 :\n\\\u0026lt;url1\\\u0026gt; https://git.oschina.net/shede333/swioslibary.git\r\\\u0026lt;url2\\\u0026gt; https://git.oschina.net/shede333/swscrollbar.git\r\\\u0026lt;url3\\\u0026gt; https://github.com/shede333/CoreAnimationTestSW.git\r  首先，先增加第一个地址 git remote add origin   然后增加第二个地址 git remote set-url \u0026ndash;add origin   增加第三个地址 git remote set-url \u0026ndash;add origin   \u0026hellip;.依次类推\n  这样就完成了添加多个地址到origin库中了， 以后只要使用git push origin master 就可以一次性push到3各库里面了(使用git push也可)\n  原理解析\ngit remote set-url \u0026ndash;add origin 就是往当前git项目的config文件里增加一行记录\n[remote \u0026quot;origin\u0026quot;]\rurl = https://git.nju.edu.cn/demsheng/QtVTKHelloWorld.git\rfetch = +refs/heads/*:refs/remotes/origin/*\rurl = https://github.com/demsheng/QtVTKHelloWorld.git\r[branch \u0026quot;main\u0026quot;]\rremote = origin\rmerge = refs/heads/main\r  注意\n使用git push origin master时，你可以push到origin的多个url地址， 但是使用 git pull时，只能拉取origin里的一个url地址(即fetch-url，如上图)，这个fetch-url默认为 你添加的到origin的第一个地址， 如果你想更改，只需要更改config文件里，那三个url的顺序即可，fetch-url会直接对应排行第一的那个utl连接。\n  https://www.cnblogs.com/hsd1727728211/p/5331651.html\n    "
},
{
	"uri": "https://sheng.geovbox.com/git/port/",
	"title": "修改默认端口号",
	"tags": [],
	"description": "",
	"content": "由于安全或者其它原因，我们可能会修改默认的SSH服务端口号，默认情况下，已有的git项目在pull或者push的时候会报错。现在假设原来的项目的remote设置为git@www.xxx.com:marks/web.git，将服务器SSH默认端口修改为1234后，导致push出错。有三种解决方式：\n  直接修改URL为SSH://开头\n git remote set-url origin ssh://git@www.xxx.com:1234/marks/web.git   修改本地配置文件\n #映射一个别名 vi ~/.ssh/confighost xxxhostname www.xxx.comport 1234   克隆仓库的时候直接指定端口\n git clone ssh://git@www.xxx.com:1234/marks/web.git   作者：marksdev\n链接：https://www.jianshu.com/p/b3dcd55ddc9d\n来源：简书\n简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n"
},
{
	"uri": "https://sheng.geovbox.com/rocks/reboot/",
	"title": "重启集群",
	"tags": [],
	"description": "",
	"content": "重启集群\nrocks run host command=\u0026#34;shutdown -h now\u0026#34; "
},
{
	"uri": "https://sheng.geovbox.com/boost/",
	"title": "boost",
	"tags": [],
	"description": "",
	"content": "李长圣学习boost的笔记。\nboost的link 和 runtime-link，搭配shared 和 static 转自：http://blog.csdn.net/yasi_xi/article/details/8660549\nlink：生成动态链接库/静态链接库。生成动态链接库需使用shared方式，生成静态链接库需使用 static方式。\nruntime-link：动态/静态链接C/C++运行时库。同样有shared和static两种方 式，这样runtime-link和link一共可以产生4种组合方式。虽然它和link属性没有直接关系，但我们习惯上，一个工程如果用动态链接那么所有库都用动态链接，如果用静态链接那么所有库都用静态链接。所以这样其实只需要编译2种组合即可，即link=shared runtime-link=shared和link=static runtime-link=static。\n还有人总结windows下boost库的命名特点：\nlink=static runtime-link=static 得到 libboostxxxxx.lib link=shared runtime-link=shared 得到 boostxxxx.lib 和 boostxxxx.dll 由以上的文件夹层次结构基本就可以得出结论： １、以“lib”开头的是“link-static”版本的，而直接以“boost”开头的是“link-shared”版本的。 ２、有“d”的为debug版本，没有的则是release版本。 ３、有“s”的为“runtime-link-static”版本，没有的则是“runtime-link-shared”版本。 ４、有“mt”的为“threading-multi”版本，没有的则是“threading-single”版本。\n一位在微软做过编译器开发的大牛是这样解释的：\n假设一个库A依赖于库B，我们自己的程序client依赖于库A，即：\n1363048971_5435 那么，link指的是client-\u0026gt;A，runtime-link指的是A -\u0026gt; B\n   配置 链接过程 运行时需要的文件     link=static runtime-link=static client通过A.a (A.lib)静态包含A；A通过B.a (B.lib)静态包含B；不关 .so .dll的事 client   link=static runtime-link=shared client通过A.a (A.lib)静态包含A；在运行时，client要动态调用B.so (B.dll) client B.so (B.dll)   link=shared runtime-link=shared client会包含A.a (A.lib)；A会包含 B.a (B.lib)；但都只保存动态库的真正实现的stub，运行时通过stub去动态加载A.so (A.dll) B.so (B.dll)中的实现 client A.so (A.dll) B.so (B.dll)   link=shared runtime-link=static client会包含A.a (A.lib)，但只包含真正实现的stub；A通过B.a (B.lib)静态包含B；运行时，client会动态调用A.so (A.dll) client A.so (A.dll)    "
},
{
	"uri": "https://sheng.geovbox.com/rocks/ch_home/",
	"title": "修改家目录",
	"tags": [],
	"description": "",
	"content": "原理: /etc/passwd 里的家目录永远不改 /home/zhangsan\nrocks 中 /exoprt 指向 一个磁盘（如 /state/partition1 ），home 在该磁盘中。 采用 autofs 自动挂载家目录到 /home/zhangsan 。\n操作如下：   在 /etc/auto.master 中设置 /home 挂载点。\n在主节点修改 vi /etc/auto.master\n/home /etc/auto.home --timeout=1200\r  在 /etc/auto.home 中设置主节点 sandbox.local 的目录 /state/sdb1_8T/home/zhangsan 为 zhangsan 的家目录。\n在主节点修改 vi /etc/auto.home\n# 挂载的目录名 挂载的主节点目录（主节点 和 计算节点公用该目录）\r#zhangsan -nfsvers=3 sandbox.local:/export/home/zhangsan # 原来\rzhangsan -nfsvers=3 sandbox.local:/state/sdb1_8T/home/zhangsan # 修改后\r  同步配置到计算节点\nrocks sync users # 同步账户信息，新建用户后必须同步后才生效，如果失败，重启再试 rocks sync config #同步集群配置信息，主机每次更改配置后必须使用该命令，否则会出错 rocks run host command=\u0026#34;shutdown -h now\u0026#34; #重启   "
},
{
	"uri": "https://sheng.geovbox.com/git/tags/",
	"title": "打标签",
	"tags": [],
	"description": "",
	"content": " git tag 列出标签 git tag -a v1.4 -m \u0026quot;my version 1.4\u0026quot; 创建标签 git show v1.4 列出标签信息和与之对应的提交信息 git push origin v1.5 推送标签到共享服务器上 git tag -d v1.5 删除本地标签 git push origin --delete v1.5 删除远程标签  列出标签   可带上可选的 -l 选项 \u0026ndash;list\n $ git tag v1.0 v2.0   1.8.5 系列标签\n $ git tag -l \u0026quot;v1.8.5*\u0026quot; v1.8.5 v1.8.5-rc0 v1.8.5-rc1 v1.8.5-rc2 v1.8.5-rc3 v1.8.5.1 v1.8.5.2 v1.8.5.3 v1.8.5.4 v1.8.5.5   创建标签   附注标签（annotated）\n $ git tag -a v1.4 -m \u0026quot;my version 1.4\u0026quot; $ git tag v0.1 v1.3 v1.4 -m 选项指定了一条将会存储在标签中的信息。 如果没有为附注标签指定一条信息，Git 会启动编辑器要求你输入信息。\n通过使用 git show 命令可以看到标签信息和与之对应的提交信息：\n$ git show v1.4 tag v1.4 Tagger: Ben Straub \u0026lt;ben@straub.cc\u0026gt; Date: Sat May 3 20:19:12 2014 -0700 my version 1.4 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number   轻量标签\n $ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 v1.4-lw v1.5 这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息：\n $ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number   共享标签 默认情况下，git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样——你可以运行 git push origin \u0026lt;tagname\u0026gt;。\n$ git push origin v1.5 Counting objects: 14, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (14/14), 2.05 KiB | 0 bytes/s, done. Total 14 (delta 3), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.5 -\u0026gt; v1.5 如果想要一次性推送很多标签，也可以使用带有 \u0026ndash;tags 选项的 git push 命令。 这将会把所有不在远程仓库服务器上的标签全部传送到那里。\n$ git push origin --tags Counting objects: 1, done. Writing objects: 100% (1/1), 160 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.4 -\u0026gt; v1.4 * [new tag] v1.4-lw -\u0026gt; v1.4-lw 现在，当其他人从仓库中克隆或拉取，他们也能得到你的那些标签。\n删除标签 要删除掉你本地仓库上的标签，可以使用命令 git tag -d \u0026lt;tagname\u0026gt;。 例如，可以使用以下命令删除一个轻量标签：\n$ git tag -d v1.4-lw Deleted tag 'v1.4-lw' (was e7d5add) 注意上述命令并不会从任何远程仓库中移除这个标签，你必须用 git push :refs/tags/来更新你的远程仓库：\n第一种变体是 git push \u0026lt;remote\u0026gt; :refs/tags/\u0026lt;tagname\u0026gt; ：\n$ git push origin :refs/tags/v1.4-lw To /git@github.com:schacon/simplegit.git - [deleted] v1.4-lw 上面这种操作的含义是，将冒号前面的空值推送到远程标签名，从而高效地删除它。\n第二种更直观的删除远程标签的方式是：\n$ git push origin --delete \u0026lt;tagname\u0026gt; 链接：https://git-scm.com/book/zh/v2/Git-%E5%9F%BA%E7%A1%80-%E6%89%93%E6%A0%87%E7%AD%BE\n"
},
{
	"uri": "https://sheng.geovbox.com/git/rm/",
	"title": "彻底删除文件",
	"tags": [],
	"description": "",
	"content": "参考: https://www.jianshu.com/p/51559937fe49\n注意：在执行彻底删除之前先备份代码，以防操作失误\n一、用 filter-branch 命令重写所有 commit 才能将文件从 Git 历史中完全移除。   删除文件\ngit filter-branch --index-filter 'git rm --cached --ignore-unmatch test/a.mp3'   删除目录\ngit filter-branch --index-filter 'git rm -rf --cached --ignore-unmatch test/'   二、依次执行下面命令\n   ``` rm -rf .git/refs/original/ git reflog expire --expire=now --all git fsck --full --unreachable git repack -A -d git gc --aggressive --prune=now git push --force ```  "
},
{
	"uri": "https://sheng.geovbox.com/web/",
	"title": "hugo网站建设",
	"tags": [],
	"description": "",
	"content": "Hugo\nSphinx\n"
},
{
	"uri": "https://sheng.geovbox.com/rocks/share/",
	"title": "共享主节点磁盘",
	"tags": [],
	"description": "",
	"content": " 主节点，设置自动挂载，磁盘 /dev/sdb1\n在主节点修改 /etc/fstab  #2017/11/28 lichangsheng add sdb1 and sdc1 # home /dev/sdb1 /state/sdb1_8T ext3 defaults 0 0 主节点，设置nfs，让计算节点共享目录 /state/sdb1_8T\n在主节点修改 /etc/exports  # all nodes share home /state/sdb1_8T 10.10.1.1(rw,async,no_root_squash) 10.10.1.0/255.255.255.0(rw,async) 主节点，修改家目录挂载点\nvi /etc/passwd # 这里的家目录永远不改 /home/zhangsan\nvi /etc/auto.home # 在这里修改家目录挂载点  #zhangsan -nfsvers=3 sandbox.local:/export/home/zhangsan # 原来\rzhangsan -nfsvers=3 sandbox.local:/state/sdb1_8T/home/zhangsan # 修改后\r集群配置信息同步，重启  rocks sync users # 同步账户信息，新建用户后必须同步后才生效，如果失败，重启再试 rocks sync config #同步集群配置信息，主机每次更改配置后必须使用该命令，否则会出错 rocks run host command=\u0026#34;shutdown -h now\u0026#34; #重启 "
},
{
	"uri": "https://sheng.geovbox.com/os/",
	"title": "系统安装",
	"tags": [],
	"description": "",
	"content": " win10 ubuntu18 双系统安装  "
},
{
	"uri": "https://sheng.geovbox.com/rocks/auto_backup/",
	"title": "自动备份",
	"tags": [],
	"description": "",
	"content": "1. 设置计划 vi /etc/crontab # every 2 min #*/2 * * * * root /home/zhangsan/backup.sh # run backup.sh every 30 days * * */30 * * root /root/backup.sh 2. 编写命令脚本 vi /root/backup.sh #1. 先拷贝数据 cp -r /home/zhangsan /mnt/sda1 #数据存在/home/zhangsan目录下，备份到/mnt/sda1目录下，先将数据拷过来 #2. 打包 tar -zcPvf /mnt/sda1/zhangsan_$(date \u0026#34;+%Y%m%d\u0026#34;).tar.gz /mnt/sda1/zhangsan #将数据所在文件夹zhangsan打包 _%H%M #3. 删除临时文件内容 rm -rf /mnt/sdc1/zhangsan #4. 移动 find /mnt/sdc1 -mtime 60 -name \u0026#34;zhangsan_*.tar.gz\u0026#34; -exec mv {} /mnt/zhangsan/canDelIfOverOneYear ; # 移动该文件夹下超过60天的文件，到canDelIfOverOneYear文件夹 #5. 删除超过一年的文件 find /mnt/sdc1/canDelIfOverOneYear -mtime 365 -name \u0026#34;*.tar.gz\u0026#34; -exec rm -rf {} \\; #删除该文件夹下超过365天的文件 -mtime 365 超过365天 -cmin +1 超过一分钟 "
},
{
	"uri": "https://sheng.geovbox.com/rocks/ssh/",
	"title": "ssh",
	"tags": [],
	"description": "",
	"content": "ssh免密码登陆  在A机下生成公钥/私钥对  ssh-keygen -t rsa 然后三次回车就可以了。 它在 /home/lichangsheng 下生成 .ssh 目录，.ssh 下有 id_rsa 和 id_rsa.pub 2. 把A机下的id_rsa.pub复制到B机下，在B机的 ~/.ssh/authorized_keys 文件里，我用scp复制。（如果B机器没有.ssh和authorized_keys文件则创建这个文件夹和文件先）\nscp /home/lichangsheng/.ssh/id_rsa.pub li_changsheng@ip:/home/li_changsheng/.ssh/id_rsa_g3.pub\rB机把从A机复制的 id_rsa.pub 添加到 ~/.ssh/authorzied_keys 文件里。  cat ~/.ssh/id_rsa_g3.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys 修改ssh登录端口号  首先修改配置文件 vim /etc/ssh/sshd_config 找到 #Port 22 一段，这里是标识默认使用22端口，修改为如下：  Port 22　Port 50000\r然后保存退出 3. 执行 /etc/init.d/sshd restart ，这样SSH端口将同时工作与22和50000上。\nssh通过代理连接服务器 引自　ssh通过代理连接服务器\n单位联网只能通过http代理联网，可以采用下面配置连接外网的主机.\n编辑ssh客户端配置文件 /etc/ssh/ssh_config ,加入：\nHost yinhw #别名，可以不设置\rHostname 52os.net #域名或者ip如114.*.*.*\rUser zhangsan\rPort 8080\r#IdentityFile 证书路径\r#### proxy.beijing.net 8080为http代理\rProxyCommand corkscrew proxy.beijing.net 8080 %h %p 使用下面命令连接即可：\nssh yinhw\rssh反向隧道 引自　https://blog.csdn.net/u011539200/article/details/88392446\n  场景\nA机，在公司内网。B机，在公网，有固定公网IP地址。C机，在家里。 需要一个功能：在家里，从C机登陆到B机，然后，登陆B机的某个端口，能进入到A机，这样，可以操作A机上的各种资料。\n  步骤\n首先，在B机上建立一个账号，用于ssh隧道\nadduser userssh\ruserssh专用于ssh隧道。\n修改 /etc/ssh/shhd_config ，把GatewayPorts打开:\nGatewayPorts yes\r然后\nservice sshd restart\r重启启动服务。\n  在内网的A机执行：\nssh -o TCPKeepAlive=yes -o ServerAliveInterval=30 -Nf -R 6000:127.0.0.1:22 userssh@43.110.20.200\r 把A机的22端口，映射到B机6000端口。其中，43.110.20.200是B机的公网IP。\n  在公网B机执行\nssh -p 6000 bri@localhost\r就可以登陆到A机。\n  在C机，先登陆到B机，再从B机登陆到A机，即可操作A机的各种资料。\n  持续连接问题，务必要有一个任何情况下都能生效的重连机制，至少断电重启之后就一定可以连上。比如，需要一个开机启动的服务，这个服务，每隔一分钟，用fabric登录公网主机，然后从公网主机登录内网主机，看看是否能成功，如果成功，表明反向隧道是可用的，如果不成功，反向隧道是不可用的，需要关闭久的，开启新的。\nhttp://www.cnblogs.com/shengulong/p/7553920.html\nhttp://www.cnblogs.com/shengulong/p/7553920.html\nhttps://blog.csdn.net/wangfei8348/article/details/60886006/\nSSH 保持连接 （解决Broken pipe） 在使用SSH客户端进行连接管理的时候如果长时间不输入命令， 服务器会自动断开连接， 尤其是有的人使用SSH作为代理连接这样的情况更是突出， 因此我在网上搜集了可以让 SSH 保持连接的方法与大家分享\n在服务器端， 可以让服务器发送“心跳”信号测试提醒客户端进行保持连接 通过修改 sshd 的配置文件，能够让 SSH Server 发送“心跳”信号来维持持续连接，下面是设置的内容\n打开服务器 /etc/ssh/sshd_config ，我在最后增加一行\n ClientAliveInterval 60\rClientAliveCountMax 1\r这 样，SSH Server 每 60 秒就会自动发送一个信号给 Client，而等待 Client 回应，（注意：是服务器发心跳信号，不是客户端，这个有别于一些 FTP Client 发送的 KeepAlives 信号哦～～～），如果客户端没有回应，会记录下来直到记录数超过 ClientAliveCountMax 的值时，才会断开连接。\n  网卡休眠\n网卡休眠造成的，设置关闭：\n修改 /etc/grub.conf ，在kernel行末尾追加 pcie_aspm=off\n  启动重连\n加入到启动脚本\n  主机休眠，\n  断网后重连\n  xshell 设置隧道 A能连B，B能连C． A想连接C，先建立一条B-\u0026gt;C的隧道．\n A的xshell中设置连接B的ip，端口，可登录到B的用户 隧道设置如下： 源主机 127.0.0.3 侦听端口 12345 目标主机 C的ip 侦听端口 22 A的xshell中设置连接127.0.0.3，端口　12345，可登录到C的用户 这里，在A中登录127.0.0.3时，会自动通过设置的隧道登录到目标主机 C  "
},
{
	"uri": "https://sheng.geovbox.com/nju/",
	"title": "博士毕业材料",
	"tags": [],
	"description": "",
	"content": "博士学位申请书 原件 2 份 盲审评阅书（或者附表二） 2份\r5张答辩表决票 1份\r评阅人和答辩委员会名单表 2份\r交院系研究生秘书\r 学位论文 6份 国家图书馆封面 （无签字） 1份\r南大封面线装本(将作者签名的《学位论文出版授权书》装订在学位论文最后一页) 1份\r南大封面的线装本(有导师签字、答辩日期、学号) 1份 交 校学位办\r 另外\n南大封面的线装本(有导师签字、答辩日期、学号) 3份 交 地球科学与工程学院\r 发表论文目录列表+论文全文（导师首页签字） 2份 1份 交 校学位办\r1份 交院系研究生秘书\r 学位论文评审材料 2份 注意：不需要论文全文\r "
},
{
	"uri": "https://sheng.geovbox.com/rocks/sge/",
	"title": "SGE",
	"tags": [],
	"description": "",
	"content": "  qstat -u \\* 查看所有任务\n  qstat -f 查看所有计算节点任务占用情况\n  qsub -l h=sand-0-0 sge.sh 把 sge.sh 提交到 sand-0-0 节点\n  任务一直 qw 状态\n  情况一：SGE未启动，首先登录子节点，启动服务\ncd $SGE_ROOT/default/common/ sudo ./sgeexecd start    情况二：SGE未添加集群队列\nSGE部署参考 http://www.chenlianfu.com/?p=2441 并行环境设置 http://blog.chinaunix.net/uid-24404943-id-3480812.html\n  (不确定是否需要重新安装SGE) ，安装方法见 http://gridscheduler.sourceforge.net/CompileGridEngineSource.html\n% tar zvxf SGE6.2u5p2.tar.gz % cd SGE6.2u5p2/source % ./aimk -no-java -no-jni -no-secure -spool-classic -no-dump -only-depend % ./scripts/zerodepend % ./aimk -no-java -no-jni -no-secure -spool-classic -no-dump depend % ./aimk -no-java -no-jni -no-secure -spool-classic -no-dump % export SGE_ROOT=/opt/SGE6 % mkdir $SGE_ROOT % scripts/distinst -all -local -noexit % cd $SGE_ROOT % ./install_qmaster % ./install_execd ``\n  添加all.q集群队列 qconf -aq all.q\n  修改all.q集群队列配置 qconf -mq all.q\nqname all.q #这里需要配置计算节点 hostlist node0.local node3.local node4.local node5.local \\ node6.local node7.local node8.local node9.local \\ node10.local node11.local node12.local node13.local \\ compute-0-15.local seq_no 0 load_thresholds np_load_avg=1.75 suspend_thresholds NONE nsuspend 1 suspend_interval 00:05:00 priority 0 min_cpu_interval 00:05:00 processors UNDEFINED qtype BATCH INTERACTIVE ckpt_list NONE #这里需要配置并行环境 orte pe_list orte make rerun FALSE #这里需要配置每个计算节点运行的最大线程数 slots 8 tmpdir /tmp shell /bin/csh prolog NONE epilog NONE shell_start_mode posix_compliant starter_method NONE suspend_method NONE resume_method NONE terminate_method NONE notify 00:00:60 owner_list NONE user_lists NONE xuser_lists NONE subordinate_list NONE complex_values NONE projects NONE xprojects NONE ``\n  添加并行化环境 qconf -ap orte\n  修改并行化环境 qconf -mp orte\npe_name orte #这里设置并行环境最大线程数 slots 100 user_lists NONE xuser_lists NONE start_proc_args /bin/true stop_proc_args /bin/true allocation_rule $pe_slots control_slaves FALSE job_is_first_task TRUE urgency_slots min accounting_summary FALSE `` 5 SGE命令\nqconf -ae hostname 添加执行主机 qconf -de hostname 删除执行主机 qconf -sel 显示执行主机列表 qconf -ah hostname 添加管理主机 qconf -dh hostname 删除管理主机 qconf -sh 显示管理主机列表 qconf -as hostname 添加提交主机 qconf -ds hostname 删除提交主机 qconf -ss 显示提交主机列表 qconf -ahgrp groupname 添加主机用户组 qconf -mhgrp groupname 修改主机用户组 qconf -shgrp groupname 显示主机用户组成员 qconf -shgrpl 显示主机用户组列表 qconf -aq queuename 添加集群队列 qconf -dq queuename 删除集群队列 qconf -mq queuename 修改集群队列配置 qconf -sq queuename 显示集群队列配置 qconf -sql 显示集群队列列表 qconf -ap PE_name 添加并行化环境 qconf -mp PE_name 修改并行化环境 qconf -dp PE_name 删除并行化环境 qconf -sp PE_name 显示并行化环境 qconf -spl 显示并行化环境名称列表 qstat -f 显示执行主机状态 qstat -u user 查看用户的作业 qhost 显示执行主机资源信息 ``\n通过使用命令qconf -mq queuename来对队列进行配置。修改hostlist来配置该队列可以使用执行主机；修改slots来配置各台执行主机可使用的线程数。从而对队列的计算资源进行设置。 部署完毕SGE后，会生成一个默认主机用户组@allhosts（未生成），它包含所有的执行节点；生成一个默认的all.q队列名（未生成），它包含所有节点所有计算资源。默认的队列包含的计算资源是最大的。\n      设置每个用户使用CPU核的上限\nqconf -mrqs\n{ name peruser_limit description \u0026quot;per user rule sets\u0026quot; enabled TRUE limit users {*} to slots=48 }  `48` 表示每个用户最多能用的CPU核数   以下参考自\n  查看主机情况 qhost -q\n BIP\t正常 E\t错误状态 a\t警告(a generic indicator of badness) u\t无法连接 d\t被管理员设置无法使用 可以通过下列方法对某个队列上的的节点进行操作 清除错误\tqmod -c all.q@cca-train02 设置节点不可用 qmod -d all.q@cca-train02 设置节点可用 qmod -e all.q@cca-train02 重启节点，详细操作见后    查看进程运行情况 qstat -f\n   状态码 详细信息     r 正在执行   t 把节点跑死了，请杀掉，不可等，占用大量资源   s 被暂时挂起，往往是由于优先级更高的job抢占了资源   dr/dt 节点挂了之后，删除任务会出现这个状态，只有节点重启任务才会消失   qw 正在等待，一旦有计算资源会马上执行   Eqw job的提交产生错误   hqw 该job依赖于其它正在执行的job，待前面的job执行完毕后再开始执行    qstat -f 结果中的states\n(a)larm, (u)nreachable, (E)rror state (au) whenever: - A node is down - A node is hung/frozen - Network problems  遇到错误状态怎么办？ - 查看某一个任务的详细情况,找到错误 ``` qstat -j \u0026lt;job-id\u0026gt; qalter -w v job-id ``` - 将某个队列从错误状态转变回正常状态 ``` qmod -c all.q ``` - 遇到 `dr/dt` 状态请依次尝试下方的解决方法 参考网址 ``` qdel -j \u0026lt;job-id\u0026gt; qdel -f \u0026lt;job-id\u0026gt; sudo qdel -f \u0026lt;job-id\u0026gt; ```   重启\n  [centos]:\ncd $SGE_ROOT/default/common/ sudo ./sgemaster start sudo ./sgeexecd start    [linux]:\nsudo /etc/init.d/gridengine-exec stop      "
},
{
	"uri": "https://sheng.geovbox.com/singularity/",
	"title": "singularity",
	"tags": [],
	"description": "",
	"content": "为了在centos等集群上使用yade，采用singularity下载ubuntu的容器，在该容器中安装yade，之后打包成sif可执行文件，该文件可用直接在centos集群中执行,运行方法如下：\nsingularity exec ubuntu2004.simg yade --version\r修改yade官方镜像 singularity build yade2020.sif docker:registry.gitlab.com/yade-dev/docker-prod:ubuntu20.04\r#运行yade，出现以下错误，运行如下内容修复\r#ImportError: libQt5Core.so.5: cannot open shared object file: No such file or directory\rsingularity build --sandbox yade2020/ yade2020.simg\rsu\rsingularity shell --writable ubuntu2004/\r#参考下文更新为国内源，加快下载速度\rapt-get install libqt5core5a\rstrip --remove-section=.note.ABI-tag /lib/x86_64-linux-gnu/libQt5Core.so.5\ryade --version\rexit\rsingularity build yade2020.simg yade2020/\rsingularity exec ubuntu2004.simg yade --version\r从ubuntu20.04镜像构建包含yade的ubuntu2004.simg  采用系统：centos 7.0 sif 仅可读 sandbox 可修改，增删软件  #1. centos 中安装 singularity yum install singularity\r#2. 从远程下载ubuntu20.04镜像，并构建为sandbox\rsingularity build --sandbox ubuntu2004/ docker://homebrew/ubuntu20.04\r##或者\r##2.从远程下载ubuntu20.04镜像，并构建为sif。之后，sif转为sandbox\r#singularity build ubuntu2004.sif docker://homebrew/ubuntu20.04\t#singularity build --sandbox ubuntu2004/ ubuntu20yade2018.simg\r#sandbox中安装yade\r#用root增删软件，sandbox内外都为root\rsu\r#########################################################################\r#交互式进入sandbox\rsingularity shell --writable ubuntu2004/\r#更新为国内源，加快下载速度\rcp /etc/apt/sources.list /etc/apt/sources.list.backup\rapt update\rapt install vim\rvim /etc/apt/sources.list\r#将以下信息写入sources.list\r###\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal main restricted\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates main restricted\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal universe\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates universe\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal multiverse\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-updates multiverse\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-backports main restricted universe multiverse\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security main restricted\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security universe\rdeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu/ focal-security multiverse\r###\r#安装yade\rapt install yade\r#运行yade，出现以下错误，运行如下内容修复\r#ImportError: libQt5Core.so.5: cannot open shared object file: No such file or directory\rapt-get install libqt5core5a\rstrip --remove-section=.note.ABI-tag /lib/x86_64-linux-gnu/libQt5Core.so.5\r#sandbox内测试\ryade --version\r#推出sandbox\rexit\r#########################################################################\r#4. sandbox转为simg(sif)，后缀名随便\rsingularity build ubuntu2004.simg ubuntu2004/\r#如果提示找不到tmp，centos中运行如下命名\rmkdir /home/lichangsheng/tmp\r#转成普通用户\rsu lichangsheng\r#5. sandbox外测试，1）本机测试，2）复制ubuntu2004.simg到centos集群，用如下命令测试\rsingularity exec ubuntu2004.simg yade --version\rslurm 北京并行超算云中使用 ubuntu20yade2018.simg  直接运行 srun -n 1 -c 12 singularity exec /path/to/ubuntu20yade2018.simg yade -j12 /path/to/GeoStructLab/shear/gen.py ./mat.txt 采用 Slurm 提交计算 sbatch job.sh , job.sh 中内容参考：  #!/bin/bash\r#SBATCH --job-name=test\r#SBATCH --partition=v6_384\r#SBATCH -n 1\r#SBATCH -c 8\r#SBATCH -t 14400\r#SBATCH --output=%j.out\r#SBATCH --error=%j.err\rsource /public1/soft/modules/module.sh\rmodule load singularity/3.5.3-wzm\rexport GSL=/path/to/GeoStructLab\r#singularity exec /path/to/ubuntu20yade2018.simg yade --version\r#time singularity exec /path/to/ubuntu20yade2018.simg yade -n -x -j8 /path/to/scripty.py\rtime srun -n 1 -c 8 singularity exec /path/to/yade2020.simg yade -n -x -j8 /path/to/script.py ./matCohFricCai2016.txt\r特别注意：\n script.py 脚本中， 需要设置 O.run(wait=True) ，即不进入交互模式，一直等待计算完成。 -n 不启动GUI界面 -x 执行完 script.py ，即退出yade  LSF 南京大学高性能计算中心使用 ubuntu20yade2018.simg  直接运行 singularity exec /path/to/ubuntu20yade2018.simg yade -j12 /path/to/scripy.py 采用 LSF 提交计算 bsub \u0026lt; lsf.sh ， lsf.sh 中内容参考：  #!/bin/bash\r#\r#BSUB -J cs\r#BSUB -q mpi\r#BSUB -n 24\r#BSUB -R \u0026quot;span[ptile=24]\u0026quot;\r# for singularity\rexport PATH=/opt/singularity-3.7.0/bin:$PATH\rexport LD_LIBRARY_PATH=/opt/singularity-3.7.0/lib/singularity:$LD_LIBRARY_PATH\rexport MANPATH=$MANPATH:/opt/singularity/3.7.0/share/man\r#singularity exec /path/to/ubuntu20yade2018.simg yade --version\rtime singularity exec /path/to/ubuntu20yade2018.simg yade -n -x -j24 /path/to/script.py\r特别注意：\n script.py 脚本中， 需要设置 O.run(wait=True) ，即不进入交互模式，一直等待计算完成。 -n 不启动GUI界面 -x 执行完 script.py ，即退出yade  进阶：Singularity入门之运行容器  https://cloud.tencent.com/developer/article/1478616  下载已存在镜像 和Docker类似，要运行 Singularity 也需要先获取镜像，Singularity 可以从Singularity Hub 或者 Docker Hub 来获取已存在的镜像。\nSingularity Hub\rsingularity -d build lolcow.simg shub://GodloveD/lolcow\rDocker Hub\rsingularity -d build lolcow.simg docker://godlovedc/lolcow\rsingularity -d build centos.simg docker://centos\rsingularity -d build ubuntu.simg docker://ubuntu\r交互模式运行 $ singularity shell ubuntu.simg\rSingularity: Invoking an interactive shell within container...\rSingularity ubuntu.simg:~\u0026gt; pwd\r/home/admin\rSingularity ubuntu.simg:~\u0026gt; id\ruid=1000(admin) gid=1000(admin) groups=1000(admin),10(wheel)\r执行一个命令并退出 $ singularity exec ubuntu.simg bash -c \u0026quot;pwd \u0026amp;\u0026amp; id\u0026quot;\r/home/admin\ruid=1000(admin) gid=1000(admin) groups=1000(admin),10(wheel)\r运行一个容器 $ singularity run ubuntu.simg\radmin@bdmaster:~$ pwd\r/home/admin\radmin@bdmaster:~$ id\ruid=1000(admin) gid=1000(admin) groups=1000(admin),10(wheel)\r后台运行容器实例 启动实例\r$ singularity instance.start ubuntu.simg test1\r$ singularity instance.start ubuntu.simg test2\r查看实例 $ singularity instance.list\rDAEMON NAME PID CONTAINER IMAGE\rtest1 14172 /home/admin/ubuntu.simg\rtest2 14239 /home/admin/ubuntu.simg\r操作实例 可以通过 shell, exec, run 命令来连到容器中运行命令\n 使用 shell 命令连入容器  $ singularity shell instance://test1\rSingularity ubuntu.simg:~\u0026gt; ps -ef\rUID PID PPID C STIME TTY TIME CMD\radmin 1 0 0 03:14 ? 00:00:00 singularity-instance: admin [test1]\radmin 3 0 3 03:14 pts/0 00:00:00 /bin/bash --norc\radmin 4 3 0 03:14 pts/0 00:00:00 ps -ef\r 使用 exec 执行命令  $ singularity exec instance://test1 ps -ef\rUID PID PPID C STIME TTY TIME CMD\radmin 1 0 0 03:14 ? 00:00:00 singularity-instance: admin [test1]\radmin 6 0 0 03:15 pts/0 00:00:00 ps -ef\r 停止实例  $ singularity instance.stop test1\r$ singularity instance.stop test1\r 绑定目录 在 Singularity 中也可以在 shell, run, instance.start 等命令中通过 \u0026ldquo;-B\u0026rdquo; 选项来实现 Docker 中 “-v” 选项提供挂载卷的功能，比如：  $ singularity shell -B /apps:/apps ubuntu.simg\r参考网站  Singularity入门之运行容器 https://cloud.tencent.com/developer/article/1478616 Singularity入门之通过沙盒创建镜像 https://cloud.tencent.com/developer/article/1478617 Singularity构建容器镜像 https://zhuanlan.zhihu.com/p/138806519 Singularity 快速上手, 带你飞 https://blog.csdn.net/CODE_RabbitV/article/details/120440819 singularity基本用法 https://blog.csdn.net/HackerTom/article/details/116355126 Docker镜像转Singularity镜像的全过程 https://blog.csdn.net/weixin_39505820/article/details/122582164 容器 https://docs.hpc.sjtu.edu.cn/container/index.html 容器引擎 - Singularity 使用说明 https://zhuanlan.zhihu.com/p/448811231 Singularity实践教程 + Docker 转 Singularity 的避坑指南 https://blog.csdn.net/Tanqy1997/article/details/125304273 下载image https://hub.docker.com/ singularity手册 https://docs.sylabs.io/guides/3.1/user-guide/index.html  "
},
{
	"uri": "https://sheng.geovbox.com/rocks/lsf/",
	"title": "LSF",
	"tags": [],
	"description": "",
	"content": "引自　简书\n简介 LSF （Load Sharing Facility）是一个被广泛使用的作业管理系统，具有高吞吐、配置灵活的优点。通过 LSF 集中监控和调度，可以充分利用计算机的CPU、内存、磁盘等资源。\n常用命令\n bqueues：查看计算队列 bhosts：查看计算节点列表 lsload：查看负载 bsub：提交作业 bjobs：查看作业状态 bkill：终止作业 bpeek：查看作业的标准输出 bhist：作业历史信息  作业提交bsub bsub调用方法 可以通过以下三种方法使用 bsub 来提交作业：\n 直接在命令行中输入完整参数： 进入 bsub 环境交互提交： 编写作业提交脚本供 bsub 处理。  直接输入完整参数 可以直接在 bsub 的命令行中输入完整的参数来提交一个作业，比如：\n$ bsub -n 4 -q example-queue -o example.out ./example \u0026quot;-input data.txt\u0026quot; 其中所用的参数说明如下：\n -n 指定所需的处理器数目； -q 指定作业运行的队列； -o 指定作业运行信息的输出文件； \u0026ldquo;-input data.txt\u0026rdquo; 是传递给执行程序 example 的命令行参数。  这种方式比较适合提交简单的作业，更复杂的作业控制需要编写作业脚本。\n使用作业提交脚本 LSF 作业脚本本质上也是一个 shell 脚本，在其中可以用 #BSUB开头的行来指明 bsub作业参数。下面是一个 LSF 作业脚本示例：\n# example.lsf #BSUB -L /bin/bash #BSUB -J example-mpi4py #BSUB -q example-queue #BSUB -n 4 #BSUB -o example.out #BSUB -e example.err mpirun python example-mpi4py.py 其中各参数说明如下：\n -L 指明所用的执行 shell，默认会调用 /bin/sh 执行脚本； -J 指定作业名； -q 指定作业队列； -n 指定作业所需的进程数； -o 指定作业的标准输出文件； -e 指定作业的错误输出文件。  提交作业脚本，使用下面的命令：\n$ bsub \u0026lt; example.lsf 交互式提交 在终端中输入 bsub 并回车后会进入 bsub 交互环境，在其中可输入作业参数和执行作业程序。在 bsub 交互环境下可以一次提交多个参数相同的作业，例如：\n$ bsub bsub\u0026gt; -n 4 bsub\u0026gt; -q example-queue bsub\u0026gt; -o example.out bsub\u0026gt; PROG1 bsub\u0026gt; PROG2 bsub\u0026gt; PROG3 bsub\u0026gt; Ctrl+D 使用 Ctrl+D 可退出 bsub 交互环境。\n查看作业信息 可以用 bjobs 命令查看用户正在运行中的作业：\n$ bjobs 使用 -l参数和某个作业的 JOBID，可以查看该作业的详细信息：\n$ bjobs -l JOBID 中止作业 使用 bkill 命令中止某个作业：\n$ bkill JOBID 以上简要介绍了 LSF 作业管理系统。\n"
},
{
	"uri": "https://sheng.geovbox.com/rocks/pbs/",
	"title": "PBS",
	"tags": [],
	"description": "",
	"content": "参考 https://www.jianshu.com/p/2f6c799ca147\n查看　提交　删除   qstat 查看\n  qstat -n 查看提交节点等详细信息\n  qsub pbs.sh 提交\npbs.sh　中内容：\n#PBS -N sheng ##可以给任务一个名字,方便辨识 #PBS -l nodes=1:ppn=12 ##使用1节点，每个节点12核 vboxdaily push.py vbox2jpg --dir=./data convert -delay 100 ./data/*[0-9].jpg -loop 0 ./data/process.gif   qdel 31 删除作业号为31的作业\n[zhangsan@mu01 ~]$ qsub pbs.sh 28.mu01 [zhangsan@mu01 ~]$ qstat Job id Name User Time Use S Queue ------------------------- ---------------- --------------- -------- - ----- 31.mu01 zhangsan lichangsheng 00:00:13 R batch [zhangsan@mu01 ~]$ qdel 28 [zhangsan@mu01 ~]$ qstat Job id Name User Time Use S Queue ------------------------- ---------------- --------------- -------- - ----- 31.mu01 sheng lichangsheng 00:22:43 C batch    Job id Name User Time Use S Queue     作业号 作业名 提交人 运行的时间 作业状态 队列      通常作业状态S：\n Q 作业排队 R 作业执行 C 作业清除 E 作业退出 H 作业挂起  PBS(Portable Batch System)最初由NASA的Ames研究中心开发，主要为了提供一个能满足异构计算网络需要的软件包，用于灵活的批处理，特别是满足高性能计算的需要，如集群系统、超级计算机和大规模并行系统。PBS的主要特点有：代码开放，免费获取；支持批处理、交互式作业和串行、多种并行作业。\n作业控制  qsub：提交作业 qdel：取消作业 qsig：给作业发送信号 qhold：挂起作业 qrls：释放挂起的作业 qrerun：重新运行作业 qmove：将作业移动到另一个队列 qalter： 更改作业资源属性  作业监测  qstat：显示作业状态 showq： 查看所有作业  节点状态  pbsnodes：列出集群中所有节点的状态和属性  PBS 作业属性 可以用两种方式设置 PBS 作业属性：\n 通过命令行参数传递给 qsub 命令； 在 PBS 脚本中以 #PBS 方式指定。  下表列出常用的 PBS 作业属性\n   属性 取值 说明     -l 以逗号分隔的资源列表 设定作业所需资源   -N 作业名称 设定作业的标准输出文件路径   -o 文件路径 设定作业的标准错误文件路径   -e 文件路径 设定作业名称   -p -1024 到 +1023 之间的整数 设定作业优先级，越大优先级越高   -q 队列名称 设定作业队列名称    比较常用的作业资源如下：\n   资源 取值 说明     nodes 节点资源构型 设定作业所需计算节点资源   walltime hh:mm:ss 设定作业所需的最大 wallclock 时间   cput hh:mm:ss 设定作业所需的最大 CPU 时间   mem 正整数，后面可跟 b，kb，mb，gb 设定作业所需的最大内存   ncpus 正整数 设定作业所需的 CPU 数目    可以用以下方法设定节点资源构型：\n 设定所需节点数：nodes=\u0026lt;num nodes\u0026gt; 设定所需节点数和每个节点上使用的处理器数目：nodes=\u0026lt;num nodes\u0026gt;:ppn=\u0026lt;num procs per node\u0026gt; 设定所用的节点：nodes=\u0026lt;list of node names separated by '+'\u0026gt;  PBS 环境变量 下表列出常用的 PBS 环境变量：\n   环境变量 说明     PBS_ENVIRONMENT 批处理作业为 PBS_BATCH，交互式作业为 PBS_INTERACTIVE   PBS_JOBID PBS 系统给作业分配的标识号   PBS_JOBNAME 用户指定的作业名称   PBS_NODEFILE 包含作业所用计算节点的文件名   PBS_QUEUE 作业所执行的队列名称   PBS_O_HOME 执行 qsub 命令的 HOME 环境变量值   PBS_O_PATH 执行 qsub 命令的 PATH 环境变量值   PBS_O_SHELL 执行 qsub 命令的 SHELL 环境变量值   PBS_O_HOST 执行 qsub 命令节点名称   PBS_O_QUEUE 提交的作业的最初队列名称   PBS_O_WORKDIR 执行 qsub 命令所在的绝对路径    提交批处理作业 用以下命令形式提交批处理作业： qsub [options] \u0026lt;control script\u0026gt;\n作业提交后一般会先排队等待，PBS 系统会根据作业的优先级和可用的计算资源来调度和执行作业。\nPBS 脚本本质上是一个 Linux shell 脚本，在 PBS 脚本中可以用一种特殊形式的注释（#PBS）作为 PBS 指令以设定作业属性。下面是一个 PBS 脚本示例：\n#!/bin/bash # file: example.pbs ### set job name #PBS -N example-job ### set output files #PBS -o example.stdout #PBS -e example.stderr ### set queue name #PBS -q example-queue ### set number of nodes #PBS -l nodes=2:ppn=4 # enter job's working directory cd $PBS_O_WORKDIR # get the number of processors NP=`cat $PBS_NODEFILE | wc -l` # run an example mpi4py job mpirun -np $NP -machinefile $PBS_NODEFILE python example_mpi4py.py 用以下命令提交该作业：qsub example.pbs\n取消或停止作业 要取消或停止一个作业，需要得到该作业的作业标识号 ，可以通过 qstat 命令获得。\n取消排队等待的作业 取消一个正在排队等待的作业，可用以下命令：qdel \u0026lt;job ID \u0026gt;\n停止正在运行的作业 要停止一个正在运行的作业，可用向其发送 KILL 信号：qsig -s KILL \u0026lt;job ID\u0026gt;\n交互式作业 交互式的计算作业通过类似于下面的命令使用：qsub -I [options]\n例如要求 2 台计算节点，运行在 example-queue 队列上的交互式作业，执行如下命令：qsub -I -l nodes=2 -q example-queue\n执行完以上命令，等 PBS 系统分配好资源后会进入所分配的第一台计算节点，可在其命令终端上执行交互式的计算任务，如要退出交互作业，可在终端输入 exit 命令，或使用按键 Ctrl+D 。\n"
},
{
	"uri": "https://sheng.geovbox.com/rocks/chpw/",
	"title": "设置用户密码期限",
	"tags": [],
	"description": "",
	"content": " chage -l zhangsan 查看用户密码设定情况 chage -d 0 zhangsan 强制用户登陆时修改口令 chage -M 90 zhangsan 密码有效期90天 chage -E '2014-09-30' zhangsan # 设置账号的有效期是2014-09-30  参数说明  -m 密码可更改的最小天数。为零时代表任何时候都可以更改密码。 -M 密码保持有效的最大天数。 -W 用户密码到期前，提前收到警告信息的天数。 -E 帐号到期的日期。过了这天，此帐号将不可用。 -d 上一次更改的日期 -i 停滞时期。如果一个密码已过期这些天，那么此帐号将不可用。 -l 例出当前的设置。由非特权用户来确定他们的密码或帐号何时过期。  "
},
{
	"uri": "https://sheng.geovbox.com/rocks/ip/",
	"title": "IP配置",
	"tags": [],
	"description": "",
	"content": "参考\n  ifconfig 查看IP地址\n em1 Link encap:Ethernet HWaddr **** inet addr:192.168.1.32 Bcast:10.10.1.255 Mask:255.255.255.0 # 集群局域网ip地址 inet6 addr: **** Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:11297 errors:0 dropped:0 overruns:0 frame:0 TX packets:4578 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:1695966 (1.6 MiB) TX bytes:652377 (637.0 KiB) Interrupt:35 em2 Link encap:Ethernet HWaddr **** inet addr:114.2.1.1 Bcast:114.2.255.255 Mask:255.255.240.0 # 外网ip地址，我们都是连接这个ip inet6 addr: ***** Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:748 errors:0 dropped:0 overruns:0 frame:0 TX packets:1824 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:80412 (78.5 KiB) TX bytes:194872 (190.3 KiB) Interrupt:38 lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:16436 Metric:1 RX packets:121109 errors:0 dropped:0 overruns:0 frame:0 TX packets:121109 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:26637971 (25.4 MiB) TX bytes:26637971 (25.4 MiB)    /etc/sysconfig/network-scripts/ifcfg-em2 中保存了IP配置信息\nmore /etc/sysconfig/network-scripts/ifcfg-em2 动态IP配置\nDEVICE=em2 HWADDR=43:21:32:43:21:32 #IPADDR=114.123.123.123 #注释 #NETMASK=255.255.255.0 #注释 BOOTPROTO=dhcp #dhcp动态获取IP ONBOOT=yes #启用该网口 MTU=1500  `more /etc/sysconfig/network-scripts/ifcfg-em2` 静态IP配置  DEVICE=em2 HWADDR=43:21:32:43:21:32 IPADDR=114.123.123.123 #设置的静态IP地址 NETMASK=255.255.255.0 #子网掩码 BOOTPROTO=static #静态IP ONBOOT=yes #启用该网口 MTU=1500    重启网络 service network restart\n  实例 东华理工大学 并行计算实验室\n外网 vi /etc/sysconfig/network-scripts/ifcfg-eth1\nDEVICE=eth1 TYPE=Bridge IPADDR=AAA.BBB.CCC.150 NETMASK=255.255.255.0 GATEWAY=AAA.BBB.CCC.1 BOOTPROTO=static ONBOOT=yes MTU=1500    "
},
{
	"uri": "https://sheng.geovbox.com/rocks/login/",
	"title": "登录进入bash",
	"tags": [],
	"description": "",
	"content": " 问题：用户目录消失，登录进入 bash 原因：/var 满，导致 autofs 无法运行，/share 和 /home 无法自动挂载， 解决办法： mv /var/log/messages-20190825 /mnt/sdc1_data_backup/var_log  "
},
{
	"uri": "https://sheng.geovbox.com/rocks/rocks_install/",
	"title": "rocks 重装",
	"tags": [],
	"description": "",
	"content": "1. 依赖库重装 1. 安装　convert 命令   方法一：参考　https://blog.csdn.net/gaofuqi/article/details/26698547\ncd /home/li_changsheng/bin/\rwget http://www.imagemagick.org/download/ImageMagick-6.8.9-1.tar.gz\rtar xvf ImageMagick-6.8.9-1.tar.gz\rcd ImageMagick-6.8.9-1\r./configure --prefix=/home/li_changsheng/bin/ImageMagick-6.8.9-1-install\rmake install\r`\n 在http://www.imagemagick.org/download/上找到合适的版本，然后下载，我选择的版本是 ImageMagick-6.9.10-71.tar.gz wget http://www.imagemagick.org/download/ImageMagick-6.8.9-1.tar.gz  解压刚才下载的文件 tar xvf ImageMagick-6.8.9-1.tar.gz\r 进入解压目录：　cd ImageMagick-6.8.9-1\r 检查配置，--prefix 重要！ ./configure --prefix=/home/li_changsheng/bin/ImageMagick-6.8.9-1-install\r  如果发现没有安装jpeg（如下图），则必须先安装jpeg\n 安装jpeg：  yum install libjpeg* libpng* freetype* gd*\r`\n 安装ImageMagick     make install ``` 输入convert -resize 100x100 src.jpg des.jpg 执行成功，表明安装成功。\n方法二：在每个节点运行　yum install ImageMagick  2. 系统重装 参考　http://www.rocksclusters.org/assets/usersguides/roll-documentation/base/6.2/install-frontend.html\n  Rocks官网 下载 rocks6.2 系统iso，（软碟通　或者　win7自带刻录，忘记哪个可以了）刻录到光盘\n  设置光盘启动，安装主节点\n  主节点运行 insert-ethers\n  计算节点，设置网络启动，即可自动安装计算节点\n  3. 问题  如果计算节点无法登录:  rocks set host sec_attr compute attr=root_pw\rrocks sync host sec_attr compute\r如果 SGE 任务一直未　wq 状态，需要重新设置SGE，配置方法见SGE  4. 修改节点名 参考　https://blog.csdn.net/weixin_40203160/article/details/78404527\n修改单个计算节点名字   修改rocks的host名称\nrocks set host name compute-0-3 node13 rocks set host interface name node13 eth0 node13\r`\n  主节点和计算节点　/etc/hosts 中修改名字\n10.1.255.251 node13.local node13\r`\n  node13中\nmv /opt/gridengine/default/spool/compute* /opt/gridengine/default/spool/node13\r`\n  管理节点中，目录 /opt/gridengine/default/common/local_conf /opt/gridengine/default/spool/qmaster/admin_hosts /opt/gridengine/default/spool/qmaster/exec_hosts 下，文件名修改，其内容也修改\n#compute-0-3 node13\rmv /opt/gridengine/default/common/local_conf/compute-0-3.local /opt/gridengine/default/common/local_conf/node13.local\rsed -i \u0026quot;/conf_name/c\\conf_name node3.local \u0026quot; /opt/gridengine/default/common/local_conf/node13.local\rmv /opt/gridengine/default/spool/qmaster/admin_hosts/compute-0-3.local /opt/gridengine/default/spool/qmaster/admin_hosts/node13.local\rsed -i \u0026quot;/hostname/c\\hostname node3.local \u0026quot; /opt/gridengine/default/spool/qmaster/admin_hosts/node13.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-3.local /opt/gridengine/default/spool/qmaster/exec_hosts/node13.local\rsed -i \u0026quot;/hostname/c\\hostname node13.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node13.local\r`\n  重启SGE\n/etc/init.d/sgemaster.sandbox stop\r/etc/init.d/sgemaster.sandbox start\rssh node13 \u0026quot;/etc/init.d/sgeexecd.sandbox stop\u0026quot;\rssh node13 \u0026quot;/etc/init.d/sgeexecd.sandbox start\u0026quot;\r`\n  批量修改计算节点名字   修改rocks的host名称 修改前后的主机名称，使用命令 rocks list host 可以查看所有节点主机名称 1change.sh 脚本如下：\n#!/bin/bash\rrocksSetName()\r{\rrocks set host name compute-0-3 node13 rocks set host name compute-0-13 node12 rocks set host name compute-0-2 node11 rocks set host name compute-0-12 node10\rrocks set host name compute-0-1 node9\rrocks set host name compute-0-9 node8\rrocks set host name compute-0-0 node6 rocks set host name compute-0-10 node5 rocks set host name compute-0-7 node4 rocks set host name compute-0-11 node3 rocks set host name compute-0-8 node7\rrocks set host name compute-0-6 node1\rrocks set host name compute-0-14 node0\rfor i in {3..13}\rdo\rrocks set host interface name node$i eth0 node$i\rdone\rrocks set host interface name node1 eth0 node1\rrocks set host interface name node0 eth0 node0\r}\rrocksSetName\r`\n  系统主机名称的修改 在系统文件 /etc/hosts 记录的是管理节点和计算节点的内网地址和主机名称，使用vim命令做相应的修改，注意ip地址和主机名称的对应\n127.0.0.1 localhost.localdomain localhost\r10.1.255.249 compute-0-15.local compute-0-15\r10.1.255.250 node0.local node0\r10.1.255.248 node1.local node1\r10.1.255.242 node10.local node10\r10.1.255.252 node11.local node11\r10.1.255.241 node12.local node12\r10.1.255.251 node13.local node13\r10.1.255.243 node3.local node3\r10.1.255.247 node4.local node4\r10.1.255.244 node5.local node5\r10.1.255.254 node6.local node6\r10.1.255.246 node7.local node7\r10.1.255.245 node8.local node8\r10.1.255.253 node9.local node9\r10.1.1.1 sandbox.local sandbox\r172.18.127.150 sandbox.ecut.edu.cn\r`\n这是管理节点上的主机名称修改，与此相对应的，每一个计算节点上都需要做相应的修改，运行如下脚本 2change.sh ：\n#!/bin/bash\rnodeHostname()\r{\r# modify the hostname\rfor i in {3..13}\rdo\rssh node$i \u0026quot;hostname node$i.local\u0026quot;\rssh node$i sed -i \u0026quot;/HOSTNAME/c\\HOSTNAME=node$i.local\u0026quot; /etc/sysconfig/network\rdone\rssh node1 \u0026quot;hostname node1.local\u0026quot;\rssh node1 sed -i \u0026quot;/HOSTNAME/c\\HOSTNAME=node1.local\u0026quot; /etc/sysconfig/network\rssh node0 \u0026quot;hostname node0.local\u0026quot;\rssh node0 sed -i \u0026quot;/HOSTNAME/c\\HOSTNAME=node0.local\u0026quot; /etc/sysconfig/network\r# modify the files /etc/hosts\rssh node13 'sed -i \u0026quot;/10.1.255.251/c\\10.1.255.251 node13.local node13 \u0026quot; /etc/hosts'\rssh node12 'sed -i \u0026quot;/10.1.255.241/c\\10.1.255.241 node12.local node12 \u0026quot; /etc/hosts'\rssh node11 'sed -i \u0026quot;/10.1.255.252/c\\10.1.255.252 node11.local node11 \u0026quot; /etc/hosts'\rssh node10 'sed -i \u0026quot;/10.1.255.242/c\\10.1.255.242 node10.local node10 \u0026quot; /etc/hosts'\rssh node9 'sed -i \u0026quot;/10.1.255.253/c\\10.1.255.253 node9.local node9 \u0026quot; /etc/hosts'\rssh node8 'sed -i \u0026quot;/10.1.255.245/c\\10.1.255.245 node8.local node8 \u0026quot; /etc/hosts'\rssh node7 'sed -i \u0026quot;/10.1.255.246/c\\10.1.255.246 node7.local node7 \u0026quot; /etc/hosts'\rssh node6 'sed -i \u0026quot;/10.1.255.254/c\\10.1.255.254 node6.local node6 \u0026quot; /etc/hosts'\rssh node5 'sed -i \u0026quot;/10.1.255.244/c\\10.1.255.244 node5.local node5 \u0026quot; /etc/hosts'\rssh node4 'sed -i \u0026quot;/10.1.255.247/c\\10.1.255.247 node4.local node4 \u0026quot; /etc/hosts'\rssh node3 'sed -i \u0026quot;/10.1.255.243/c\\10.1.255.243 node3.local node3 \u0026quot; /etc/hosts'\rssh node1 'sed -i \u0026quot;/10.1.255.248/c\\10.1.255.248 node1.local node1 \u0026quot; /etc/hosts'\rssh node0 'sed -i \u0026quot;/10.1.255.250/c\\10.1.255.250 node0.local node0 \u0026quot; /etc/hosts'\rfor i in {3..13}\rdo\rssh node$i \u0026quot;mv /opt/gridengine/default/spool/compute* /opt/gridengine/default/spool/node$i\u0026quot;\rdone\rssh node1 \u0026quot;mv /opt/gridengine/default/spool/compute* /opt/gridengine/default/spool/node1\u0026quot;\rssh node0 \u0026quot;mv /opt/gridengine/default/spool/compute* /opt/gridengine/default/spool/node0\u0026quot;\r}\rnodeHostname\r`\n  SGE配置文件的修改 在 /opt/gridengine/default/common/local_conf 目录下存放着计算节点文件，具体如下\n-rw-r--r-- 1 sge sge 289 Nov 5 22:31 compute-0-15.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:23 node0.local\r-rw-r--r-- 1 sge sge 284 Oct 22 23:19 node10.local\r-rw-r--r-- 1 sge sge 284 Oct 22 23:18 node11.local\r-rw-r--r-- 1 sge sge 284 Oct 22 23:16 node12.local\r-rw-r--r-- 1 sge sge 283 Oct 22 22:42 node13.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:22 node1.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:22 node3.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:21 node4.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:21 node5.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:26 node6.local\r-rw-r--r-- 1 sge sge 282 Nov 6 12:30 node7.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:20 node8.local\r-rw-r--r-- 1 sge sge 283 Oct 22 23:19 node9.local\r-rw-r--r-- 1 sge sge 225 Oct 20 22:48 sandbox.local\r`\n不仅仅在这个目录，在另外两个目录下同样存放着类似文件，分别是 /opt/gridengine/default/spool/qmaster/admin_hosts , /opt/gridengine/default/spool/qmaster/exec_hosts 修改方法类似，可以使用sed命令做批量修改。脚本 3sge_set.sh 如下\n#!/bin/bash\r#sge #compute-0-3 node13\rmv /opt/gridengine/default/common/local_conf/compute-0-3.local /opt/gridengine/default/common/local_conf/node13.local\rsed -i \u0026quot;/conf_name/c\\conf_name node3.local \u0026quot; /opt/gridengine/default/common/local_conf/node13.local\rmv /opt/gridengine/default/spool/qmaster/admin_hosts/compute-0-3.local /opt/gridengine/default/spool/qmaster/admin_hosts/node13.local\rsed -i \u0026quot;/hostname/c\\hostname node3.local \u0026quot; /opt/gridengine/default/spool/qmaster/admin_hosts/node13.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-3.local /opt/gridengine/default/spool/qmaster/exec_hosts/node13.local\rsed -i \u0026quot;/hostname/c\\hostname node13.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node13.local\r# compute-0-13 node12 mv /opt/gridengine/default/common/local_conf/compute-0-13.local /opt/gridengine/default/common/local_conf/node12.local\rsed -i \u0026quot;/conf_name/c\\conf_name node12.local \u0026quot; /opt/gridengine/default/common/local_conf/node12.local\rmv /opt/gridengine/default/spool/qmaster/admin_hosts/compute-0-13.local /opt/gridengine/default/spool/qmaster/admin_hosts/node12.local\rsed -i \u0026quot;/hostname/c\\hostname node12.local \u0026quot; /opt/gridengine/default/spool/qmaster/admin_hosts/node12.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-13.local /opt/gridengine/default/spool/qmaster/exec_hosts/node12.local\rsed -i \u0026quot;/hostname/c\\hostname node12.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node12.local\r# compute-0-2 node11 mv /opt/gridengine/default/common/local_conf/compute-0-2.local /opt/gridengine/default/common/local_conf/node11.local\rsed -i \u0026quot;/conf_name/c\\conf_name node11.local \u0026quot; /opt/gridengine/default/common/local_conf/node11.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-2.local /opt/gridengine/default/spool/qmaster/exec_hosts/node11.local\rsed -i \u0026quot;/hostname/c\\hostname node11.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node11.local\r# compute-0-12 node10\rmv /opt/gridengine/default/common/local_conf/compute-0-12.local /opt/gridengine/default/common/local_conf/node10.local\rsed -i \u0026quot;/conf_name/c\\conf_name node10.local \u0026quot; /opt/gridengine/default/common/local_conf/node10.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-12.local /opt/gridengine/default/spool/qmaster/exec_hosts/node10.local\rsed -i \u0026quot;/hostname/c\\hostname node10.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node10.local\r#rocks set host name compute-0-1 node9\rmv /opt/gridengine/default/common/local_conf/compute-0-1.local /opt/gridengine/default/common/local_conf/node9.local\rsed -i \u0026quot;/conf_name/c\\conf_name node9.local \u0026quot; /opt/gridengine/default/common/local_conf/node9.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-1.local /opt/gridengine/default/spool/qmaster/exec_hosts/node9.local\rsed -i \u0026quot;/hostname/c\\hostname node9.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node9.local\r#rocks set host name compute-0-9 node8\rmv /opt/gridengine/default/common/local_conf/compute-0-9.local /opt/gridengine/default/common/local_conf/node8.local\rsed -i \u0026quot;/conf_name/c\\conf_name node8.local \u0026quot; /opt/gridengine/default/common/local_conf/node8.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-9.local /opt/gridengine/default/spool/qmaster/exec_hosts/node8.local\rsed -i \u0026quot;/hostname/c\\hostname node8.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node8.local\r#rocks set host name compute-0-0 node6 mv /opt/gridengine/default/common/local_conf/compute-0-0.local /opt/gridengine/default/common/local_conf/node6.local\rsed -i \u0026quot;/conf_name/c\\conf_name node6.local \u0026quot; /opt/gridengine/default/common/local_conf/node6.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-0.local /opt/gridengine/default/spool/qmaster/exec_hosts/node6.local\rsed -i \u0026quot;/hostname/c\\hostname node6.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node6.local\r#rocks set host name compute-0-10 node5 mv /opt/gridengine/default/common/local_conf/compute-0-10.local /opt/gridengine/default/common/local_conf/node5.local\rsed -i \u0026quot;/conf_name/c\\conf_name node5.local \u0026quot; /opt/gridengine/default/common/local_conf/node5.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-10.local /opt/gridengine/default/spool/qmaster/exec_hosts/node5.local\rsed -i \u0026quot;/hostname/c\\hostname node5.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node5.local\r#rocks set host name compute-0-7 node4 mv /opt/gridengine/default/common/local_conf/compute-0-7.local /opt/gridengine/default/common/local_conf/node4.local\rsed -i \u0026quot;/conf_name/c\\conf_name node4.local \u0026quot; /opt/gridengine/default/common/local_conf/node4.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-7.local /opt/gridengine/default/spool/qmaster/exec_hosts/node4.local\rsed -i \u0026quot;/hostname/c\\hostname node4.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node4.local\r#rocks set host name compute-0-11 node3 mv /opt/gridengine/default/common/local_conf/compute-0-11.local /opt/gridengine/default/common/local_conf/node3.local\rsed -i \u0026quot;/conf_name/c\\conf_name node3.local \u0026quot; /opt/gridengine/default/common/local_conf/node3.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-11.local /opt/gridengine/default/spool/qmaster/exec_hosts/node3.local\rsed -i \u0026quot;/hostname/c\\hostname node3.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node3.local\r#rocks set host name compute-0-8 node7\rmv /opt/gridengine/default/common/local_conf/compute-0-8.local /opt/gridengine/default/common/local_conf/node7.local\rsed -i \u0026quot;/conf_name/c\\conf_name node7.local \u0026quot; /opt/gridengine/default/common/local_conf/node7.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-8.local /opt/gridengine/default/spool/qmaster/exec_hosts/node7.local\rsed -i \u0026quot;/hostname/c\\hostname node7.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node7.local\r#rocks set host name compute-0-6 node1\rmv /opt/gridengine/default/common/local_conf/compute-0-6.local /opt/gridengine/default/common/local_conf/node1.local\rsed -i \u0026quot;/conf_name/c\\conf_name node1.local \u0026quot; /opt/gridengine/default/common/local_conf/node1.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-6.local /opt/gridengine/default/spool/qmaster/exec_hosts/node1.local\rsed -i \u0026quot;/hostname/c\\hostname node1.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node1.local\r#rocks set host name compute-0-14 node0\rmv /opt/gridengine/default/common/local_conf/compute-0-14.local /opt/gridengine/default/common/local_conf/node0.local\rsed -i \u0026quot;/conf_name/c\\conf_name node0.local \u0026quot; /opt/gridengine/default/common/local_conf/node0.local\rmv /opt/gridengine/default/spool/qmaster/exec_hosts/compute-0-14.local /opt/gridengine/default/spool/qmaster/exec_hosts/node0.local\rsed -i \u0026quot;/hostname/c\\hostname node0.local \u0026quot; /opt/gridengine/default/spool/qmaster/exec_hosts/node0.local\r`\n  重启守护进程 完成以上任务以后重启管理节点上的sgeqmaster守护进程以及所有计算节点下的sgeexecd进程，脚本 4change.sh 如下：\n#!/bin/bash\rrestartSge_execd()\r{\r/etc/init.d/sgemaster.sandbox stop\r/etc/init.d/sgemaster.sandbox start\rfor i in {3..13}\rdo\rssh node$i \u0026quot;/etc/init.d/sgeexecd.sandbox stop\u0026quot;\rssh node$i \u0026quot;/etc/init.d/sgeexecd.sandbox start\u0026quot;\rdone\rssh node1 \u0026quot;/etc/init.d/sgeexecd.sandbox stop\u0026quot;\rssh node1 \u0026quot;/etc/init.d/sgeexecd.sandbox start\u0026quot;\rssh node0 \u0026quot;/etc/init.d/sgeexecd.sandbox stop\u0026quot;\rssh node0 \u0026quot;/etc/init.d/sgeexecd.sandbox start\u0026quot;\r}\rrestartSge_execd\r`\n  查看并且检验系统作业脚本和rocks管理脚本 运行 qhost ， 可以看到结果\n  运行rocks命令， 比如 rocks sync config 或者所有计算节点运行同一个命令： rocks run host ls , 能够得出正常的输出结果即说明rocks管理脚本同样没有问题。\n  "
},
{
	"uri": "https://sheng.geovbox.com/rocks/parted/",
	"title": "格式化8T硬盘",
	"tags": [],
	"description": "",
	"content": "2T以上采用parted parted /dev/sdd p #打印当前盘信息 mklabel gpt #创建gpt格式盘 mkpart #创建分区 sdd1 #指定分区名 ext4 #指定分区类型 0 #分区起始位置 -1 #分区结束位置 p #打印当前盘信息 quit mkfs.ext4 /dev/sdd1 mount /dev/sdc1 sdc1_data_backup/ "
},
{
	"uri": "https://sheng.geovbox.com/",
	"title": "主页",
	"tags": [],
	"description": "",
	"content": "离散元数值模拟软件ZDEM开发者  李长圣@个人简历 李长圣@GitHub 李长圣@ResearchGate  个人标签 高性能计算、网站建设、集群管理、软件开发、数值模拟、构造模拟、岩土、地质\n研究兴趣  2019-现在　 主要做三维离散元并行计算（CPU/GPU）、软件开发、岩土体及构造相关的数值模拟。   博士期间　 开发了用于构造变形研究的高性能二维离散元数值模拟软件VBOX，旨在将构造变形研究从定性推向定量。   硕士期间　 主要做土石混合体，图像处理MATLAB，网格划分（有限元、有限差分FLAC3D）等方面的工作    使用的语言 C、C++、Matlab、Python、Fortran、Shell\n使用的库 OpenMP、CUDA、GUI、QT、VTK、GTK+、GTKmm、OpenGL\n使用的软件 ZDEM、VBOX、GMT、PFC2D、FLAC3D、ANSYS\n"
},
{
	"uri": "https://sheng.geovbox.com/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://sheng.geovbox.com/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://sheng.geovbox.com/credits/",
	"title": "致谢",
	"tags": [],
	"description": "",
	"content": "致谢 And a special thanks to @vjeantet for his work on docdock, a fork of hugo-theme-learn. v2.0.0 of this theme is inspired by his work.\n软件包和库  mermaid - generation of diagram and flowchart from text in a similar manner as markdown font awesome - the iconic font and CSS framework jQuery - The Write Less, Do More, JavaScript Library lunr - Lunr enables you to provide a great search experience without the need for external, server-side, search services\u0026hellip; horsey - Progressive and customizable autocomplete component clipboard.js - copy text to clipboard highlight.js - Javascript syntax highlighter modernizr - A JavaScript toolkit that allows web developers to use new CSS3 and HTML5 features while maintaining a fine level of control over browsers that don\u0026rsquo;t support  工具  Netlify - Continuous deployement and hosting of this documentation Hugo  "
}]